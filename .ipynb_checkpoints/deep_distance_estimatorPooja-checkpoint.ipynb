{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgVL5l-3sbfP",
    "outputId": "ae3adba1-79c0-45ae-d000-a9007eb668dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deep_distance_estimatorPooja.ipynb\\n\\nAutomatically generated by Colaboratory.\\n\\nOriginal file is located at\\n    https://colab.research.google.com/drive/1wD7Z_pun1_dkbuxyEwfZxy14pO5Zvgoa\\n\\nCode from Rienke on Github, from repository single_cell_segmentation\\n- only edited to try and work with data from NeuroToolBox Gong Lab\\n\\nDeep Distance Estimator is trained to learn EDT.\\nEDT is the euclidean distance transform and emasures the distance between\\ntwo pixels\\n\\n\\na deep distance estimator is trained to learn EDT. Since the Euclidean distance assumes a continuous instead of a Boolean value, pixels that are close to cell boundary have smaller values. Specifically consider the regions with blurred boundaries in the original images.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"deep_distance_estimatorPooja.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1wD7Z_pun1_dkbuxyEwfZxy14pO5Zvgoa\n",
    "\n",
    "Code from Rienke on Github, from repository single_cell_segmentation\n",
    "- only edited to try and work with data from NeuroToolBox Gong Lab\n",
    "\n",
    "Deep Distance Estimator is trained to learn EDT.\n",
    "EDT is the euclidean distance transform and emasures the distance between\n",
    "two pixels\n",
    "\n",
    "\n",
    "a deep distance estimator is trained to learn EDT. Since the Euclidean distance assumes a continuous instead of a Boolean value, pixels that are close to cell boundary have smaller values. Specifically consider the regions with blurred boundaries in the original images.\n",
    "\n",
    "MUST use conda environment\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this when running in google colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nKswcdJxsPao"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "win\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "# import cv2\n",
    "#from skimage.io import imread, imread_collection\n",
    "from scipy import signal\n",
    "import scipy.misc\n",
    "# from scipy.misc import imread\n",
    "from scipy.ndimage import filters,distance_transform_edt\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio # use im = imageio.imread(_____)\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.layers import Input,Activation,Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5Qronx2xsPaq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir_path='/Users/poojap/Documents/ProteinSensorResearch/single_cell_segmentation-master'\n",
    "main_path=dir_path+'/NMuMg_phase_contrast/training_data'\n",
    "path_train_input = main_path+'/distance_transform/train/Img'\n",
    "# no testing file\n",
    "path_test_input= main_path+'/distance_transform/testImg'\n",
    "path_train_gt = main_path+'/distance_transform/train/Bwdist'\n",
    "#no testing file\n",
    "path_test_gt=main_path+'/distance_transform/testBWdist'\n",
    "\n",
    "# what is predict?\n",
    "\n",
    "path_predict= '/content/gdrive/MyDrive/ImageSegmentationFiles/MembraneImages'\n",
    "# path_predict = '/content/gdrive/MyDrive/single_cell_segmentation-master/NMuMg_phase_contrast/training_data/distance_transform/testImg/crop_phasexy18c2cr1s8.tif'\n",
    "path_output= '/content/gdrive/MyDrive/single_cell_segmentation-master/output/deepDistanceEstimator'\n",
    "\n",
    "# This pathway is still wrong\n",
    "path_frcnn_predict=dir_path+'/frcnn_predict'\n",
    "\n",
    "nb_epoch =300\n",
    "batch_size = 10\n",
    "weight_file= dir_path + '/nmumg_reg_Pooja_5epochs.hdf5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuZYD4SZc0ha"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "56Rr3D9psPar"
   },
   "outputs": [],
   "source": [
    "#As this is a regression problem, train_label should be also normalized.\n",
    "def prep_data(path_img,path_gt):\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    img_list = sorted(listdir(path_img))\n",
    "    gt_list=sorted(listdir(path_gt))\n",
    "    i=0\n",
    "    while (i<len(img_list)):\n",
    "        img = np.array(imageio.imread(path_img +'/'+ img_list[i]),dtype=np.float64)\n",
    "        #img = np.array(imread(path_img +'/'+ img_list[i]))\n",
    "        #print img.shape\n",
    "        img=(img-np.amin(img))*1.0/(np.amax(img)-np.amin(img))#img*1.0 transform array to double\n",
    "        img=img*1.0/np.median(img)\n",
    "        img_h=img.shape[0]        \n",
    "        img_w=img.shape[1]        \n",
    "        img=np.reshape(img,(img_h,img_w,1))         \n",
    "        data.append(img)  \n",
    "        \n",
    "        gt =np.array(imageio.imread(path_gt + '/'+ gt_list[i]))\n",
    "#---------------with or without normalization-----------------------        \n",
    "        if np.count_nonzero(gt)!=0:\n",
    "            nonzero_gt=gt[gt>0]\n",
    "            gt=gt*1.0/np.median(nonzero_gt)\n",
    "\n",
    "        gt=np.reshape(gt,(img_h,img_w,1))\n",
    "        label.append(gt)\n",
    "        \n",
    "        i+=1\n",
    "    data=np.array(data)\n",
    "    label=np.array(label) \n",
    "    print(data.shape, label.shape)\n",
    "    return data, label     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vqGn85qbsPas"
   },
   "outputs": [],
   "source": [
    "def prep_prediction_data(path_img):\n",
    "    data = []\n",
    "    img_list = sorted(listdir(path_img))\n",
    "    i=0\n",
    "    while (i<len(img_list)):\n",
    "        img = np.array(imageio.imread(path_img +'/'+ img_list[i]),dtype=np.float64)\n",
    "        img=(img-np.amin(img))*1.0/(np.amax(img)-np.amin(img))#img*1.0 transform array to double\n",
    "        img=img*1.0/np.median(img)\n",
    "        img_h=img.shape[0]        \n",
    "        img_w=img.shape[1]\n",
    "        img=np.reshape(img,(img_h,img_w,1))\n",
    "        data.append(img)\n",
    "        i+=1\n",
    "    data=np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iuFF8b9ZsPas"
   },
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, kernel, filters):\n",
    "    x=Conv2D(filters, (kernel, kernel), padding='same')(input_tensor)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNVkkIBVsPas",
    "outputId": "a86217e2-92db-473e-8a3a-7373ab70c782"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 05:44:32.617953: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-12 05:44:32.619054: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'output_masks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pf/xpjm6sg57kgb63302zfdzxyr0000gn/T/ipykernel_87883/1958405660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#------------encoder layers--------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mconv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpool1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pf/xpjm6sg57kgb63302zfdzxyr0000gn/T/ipykernel_87883/20257315.py\u001b[0m in \u001b[0;36mconv_block\u001b[0;34m(input_tensor, kernel, filters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mprevious_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collect_previous_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0muser_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_all_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_collect_previous_mask\u001b[0;34m(input_tensors)\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0minbound_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_masks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m             \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Node' object has no attribute 'output_masks'"
     ]
    }
   ],
   "source": [
    "kernel = 3\n",
    "#------------encoder layers--------------------------------\n",
    "inputs = tf.keras.Input((None,None, 1))\n",
    "conv1=conv_block(inputs,kernel,filters=64)\n",
    "conv1=conv_block(conv1,kernel,filters=64)\n",
    "pool1=MaxPooling2D()(conv1)\n",
    "    \n",
    "conv2=conv_block(pool1,kernel,filters=128)\n",
    "conv2=conv_block(conv2,kernel,filters=128)\n",
    "pool2=MaxPooling2D()(conv2)\n",
    "\n",
    "conv3=conv_block(pool2,kernel,filters=256)\n",
    "conv3=conv_block(conv3,kernel,filters=256)\n",
    "conv3=conv_block(conv3,kernel,filters=256)\n",
    "pool3=MaxPooling2D()(conv3)\n",
    "\n",
    "conv4=conv_block(pool3,kernel,filters=512)\n",
    "conv4=conv_block(conv4,kernel,filters=512)\n",
    "conv4=conv_block(conv4,kernel,filters=512)\n",
    "pool4=MaxPooling2D()(conv4)\n",
    " \n",
    "conv5=conv_block(pool4,kernel,filters=512)\n",
    "conv5=conv_block(conv5,kernel,filters=512)\n",
    "conv5=conv_block(conv5,kernel,filters=512)\n",
    "pool5=MaxPooling2D()(conv5)\n",
    "\n",
    "\n",
    "#--------------------decoder layers--------------------------\n",
    "\n",
    "up6=UpSampling2D()(pool5)\n",
    "conv6=conv_block(up6,kernel,filters=512)\n",
    "conv6=conv_block(conv6,kernel,filters=512)\n",
    "conv6=conv_block(conv6,kernel,filters=512)\n",
    "\n",
    "up7=UpSampling2D()(conv6)\n",
    "conv7=conv_block(up7,kernel,filters=512)\n",
    "conv7=conv_block(conv7,kernel,filters=512)\n",
    "conv7=conv_block(conv7,kernel,filters=512)\n",
    "    \n",
    "up8=UpSampling2D()(conv7)\n",
    "conv8=conv_block(up8,kernel,filters=256)\n",
    "conv8=conv_block(conv8,kernel,filters=256)\n",
    "conv8=conv_block(conv8,kernel,filters=256)\n",
    "\n",
    "up9=UpSampling2D()(conv8)\n",
    "conv9=conv_block(up9,kernel,filters=128)\n",
    "conv9=conv_block(conv9,kernel,filters=128)\n",
    "\n",
    "up10=UpSampling2D()(conv9)\n",
    "conv10=conv_block(up10,kernel,filters=64)\n",
    "\n",
    "conv11=conv_block(conv10,kernel=1,filters=1)    \n",
    "outputs=Activation('relu')(conv11)\n",
    "\n",
    "autoencoder=Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "#autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(loss=\"mean_squared_error\", optimizer='adam', metrics=['mae','acc'])\n",
    "print ('Compiled: OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kefqAEmVsPat",
    "outputId": "ffea9225-cab1-476f-ce21-28058b21e851"
   },
   "outputs": [],
   "source": [
    "train_data, train_label = prep_data(path_train_input,path_train_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpASjUSIsPau",
    "outputId": "3f57945a-244f-43fc-c328-9e733d28954d"
   },
   "outputs": [],
   "source": [
    "#---------------------train-------------------------\n",
    "history=autoencoder.fit(train_data, train_label, batch_size=batch_size, epochs=nb_epoch, verbose=1)\n",
    "autoencoder.save_weights(weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "HRMXXILesPau",
    "outputId": "c058524d-9da6-44be-b97c-53ded824797f"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "#-------------------predict----------------------------\n",
    "autoencoder.load_weights(weight_file)\n",
    "# put htis into the test path same as predict\n",
    "predict_data=prep_prediction_data(path_predict)\n",
    "output = autoencoder.predict(predict_data, verbose=0)\n",
    "print(type(output))\n",
    "print(output.shape)\n",
    "\n",
    "#output_label=np.argmax(output[0],axis=-1)\n",
    "im=output[10][:,:,0]   \n",
    "np.save(path_output+'/reg_out.npy',im)\n",
    "data=np.load(path_output+'/reg_out.npy')\n",
    "print(im.shape)\n",
    "\n",
    "#save image to 8 bit\n",
    "\n",
    "imageio.imwrite(path_output+'/reg_out_8bit.png',im)\n",
    "#save image to the exat value\n",
    "\n",
    "# img=scipy.misc.toimage(im,high=np.max(im),low=np.min(im),mode='F')\n",
    "img = Image.fromarray(im, mode = 'F')\n",
    "img.save(path_output+'/reg_out_exact.tif')\n",
    "img.save(path_frcnn_predict+'/reg_out_exact.tif')\n",
    "plt.imshow(im)\n",
    "plt.axis('off')\n",
    "plt.savefig(path_output+'/reg_out_300dpi.tif',bbox_inches='tight',format='tif',dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPdKBrmTsPau"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "deep_distance_estimatorPooja.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
